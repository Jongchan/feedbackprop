{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback-prop on multilabel model (COCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import argparse, os, string, pdb, time\n",
    "from collections import defaultdict, OrderedDict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import data_loader\n",
    "import model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create arguments for the script below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self):\n",
    "        self.annDir = 'COCO annotation path'\n",
    "        self.imageDir = 'COCO image path'\n",
    "        self.logDir = 'trained model path'\n",
    "\n",
    "        self.imageSize = 256\n",
    "        self.cropSize = 224\n",
    "        self.batchSize = 64\n",
    "        self.startEpoch = 1\n",
    "        \n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normMean = [0.49139968, 0.48215827, 0.44653124]\n",
    "normStd = [0.24703233, 0.24348505, 0.26158768]\n",
    "normTransform = transforms.Normalize(normMean, normStd)\n",
    "\n",
    "testTransform = transforms.Compose([\n",
    "    transforms.Resize(args.imageSize),\n",
    "    transforms.CenterCrop(args.cropSize),\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Loading val object annotations...\n",
      "\n",
      "Preparing label space...\n",
      ". . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "valData = data_loader.loadValData(args, testTransform)\n",
    "valLoader = DataLoader(valData, batch_size = 64, shuffle = False, pin_memory = False, num_workers = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading test object annotations...\n",
      "\n",
      "Preparing label space...\n",
      ". . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "testData = data_loader.loadTestData(args, testTransform)\n",
    "testLoader = DataLoader(testData, batch_size = 64, shuffle = False, pin_memory = False, num_workers = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's divide the label space into \"known\" labels and \"unknown\" labels.\n",
    "* We known the true values for the \"known\" labels.\n",
    "* We don't know the true values for the \"unknown\" labels, these are the ones we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Known label-space</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>(1)</b> [oven]  <b>(2)</b> [ear]  <b>(3)</b> [towel]  <b>(4)</b> ['']  <b>(5)</b> [lamb]  <b>(6)</b> [something]  <b>(7)</b> [personal]  <b>(8)</b> [way]  <b>(9)</b> [motorcycle]  <b>(10)</b> [hot]  <b>(11)</b> [lake]  <b>(12)</b> [ice]  <b>(13)</b> [posted]  <b>(14)</b> [racket]  <b>(15)</b> [several]  <b>(16)</b> [size]  <b>(17)</b> [cluttered]  <b>(18)</b> [suit]  <b>(19)</b> [time]  <b>(20)</b> [including]  <b>(21)</b> [decorated]  <b>(22)</b> [sidewalk]  <b>(23)</b> [vase]  <b>(24)</b> [object]  <b>(25)</b> [partially]  <b>(26)</b> [kitchen]  <b>(27)</b> [person]  <b>(28)</b> [bunch]  <b>(29)</b> [event]  <b>(30)</b> [frisbee]  <b>(31)</b> [prepared]  <b>(32)</b> [furniture]  <b>(33)</b> [jet]  <b>(34)</b> [skateboarder]  <b>(35)</b> [male]  <b>(36)</b> [white]  <b>(37)</b> [french]  <b>(38)</b> [jetliner]  <b>(39)</b> [sail]  <b>(40)</b> [juice]  <b>(41)</b> [work]  <b>(42)</b> [flat]  <b>(43)</b> [bottom]  <b>(44)</b> [bull]  <b>(45)</b> [sauce]  <b>(46)</b> [pedestrian]  <b>(47)</b> ['s]  <b>(48)</b> [nose]  <b>(49)</b> [practicing]  <b>(50)</b> [horse]  <b>(51)</b> [putting]  <b>(52)</b> [mound]  <b>(53)</b> [pitcher]  <b>(54)</b> [look]  <b>(55)</b> [mustard]  <b>(56)</b> [swimming]  <b>(57)</b> [waiting]  <b>(58)</b> [truck]  <b>(59)</b> [cell]  <b>(60)</b> [vintage]  <b>(61)</b> [closeup]  <b>(62)</b> [topped]  <b>(63)</b> [seen]  <b>(64)</b> [fun]  <b>(65)</b> [sort]  <b>(66)</b> [chicken]  <b>(67)</b> [petting]  <b>(68)</b> [family]  <b>(69)</b> [drinking]  <b>(70)</b> [walk]  <b>(71)</b> [course]  <b>(72)</b> [bat]  <b>(73)</b> [broken]  <b>(74)</b> [pile]  <b>(75)</b> [tennis]  <b>(76)</b> [hair]  <b>(77)</b> [wing]  <b>(78)</b> [hard]  <b>(79)</b> [big]  <b>(80)</b> [trunk]  <b>(81)</b> [hay]  <b>(82)</b> [street]  <b>(83)</b> [television]  <b>(84)</b> [equipment]  <b>(85)</b> [surface]  <b>(86)</b> [kicking]  <b>(87)</b> [day]  <b>(88)</b> [wall]  <b>(89)</b> [party]  <b>(90)</b> [hold]  <b>(91)</b> [smoke]  <b>(92)</b> [baked]  <b>(93)</b> [decoration]  <b>(94)</b> [chair]  <b>(95)</b> [police]  <b>(96)</b> [counter]  <b>(97)</b> [among]  <b>(98)</b> [contains]  <b>(99)</b> [striped]  <b>(100)</b> [surfer]  <b>(101)</b> [name]  <b>(102)</b> [clean]  <b>(103)</b> [hole]  <b>(104)</b> [pretty]  <b>(105)</b> [hydrant]  <b>(106)</b> [terminal]  <b>(107)</b> [graze]  <b>(108)</b> [graffiti]  <b>(109)</b> [get]  <b>(110)</b> [sits]  <b>(111)</b> [remote]  <b>(112)</b> [lunch]  <b>(113)</b> [man]  <b>(114)</b> [coat]  <b>(115)</b> [lay]  <b>(116)</b> [block]  <b>(117)</b> [vest]  <b>(118)</b> [stacked]  <b>(119)</b> [keyboard]  <b>(120)</b> [tag]  <b>(121)</b> [brushing]  <b>(122)</b> [platform]  <b>(123)</b> [skier]  <b>(124)</b> [purse]  <b>(125)</b> [container]  <b>(126)</b> [cage]  <b>(127)</b> [sticker]  <b>(128)</b> [trying]  <b>(129)</b> [sunny]  <b>(130)</b> [small]  <b>(131)</b> [skiing]  <b>(132)</b> [art]  <b>(133)</b> [farm]  <b>(134)</b> [mid]  <b>(135)</b> [standing]  <b>(136)</b> [sandy]  <b>(137)</b> [2]  <b>(138)</b> [watching]  <b>(139)</b> [snowy]  <b>(140)</b> [pickup]  <b>(141)</b> [run]  <b>(142)</b> [girl]  <b>(143)</b> [pulled]  <b>(144)</b> [sky]  <b>(145)</b> [lot]  <b>(146)</b> [sliced]  <b>(147)</b> [packed]  <b>(148)</b> [fashioned]  <b>(149)</b> [direction]  <b>(150)</b> [platter]  <b>(151)</b> [lettuce]  <b>(152)</b> [river]  <b>(153)</b> [donut]  <b>(154)</b> [missing]  <b>(155)</b> [speed]  <b>(156)</b> [high]  <b>(157)</b> [face]  <b>(158)</b> [photo]  <b>(159)</b> [plane]  <b>(160)</b> [made]  <b>(161)</b> [serve]  <b>(162)</b> [tour]  <b>(163)</b> [woman]  <b>(164)</b> [mushroom]  <b>(165)</b> [tail]  <b>(166)</b> [forest]  <b>(167)</b> [breakfast]  <b>(168)</b> [box]  <b>(169)</b> [stove]  <b>(170)</b> [black]  <b>(171)</b> [ha]  <b>(172)</b> [signal]  <b>(173)</b> [pick]  <b>(174)</b> [clear]  <b>(175)</b> [variety]  <b>(176)</b> [cooking]  <b>(177)</b> [scissors]  <b>(178)</b> [five]  <b>(179)</b> [brightly]  <b>(180)</b> [refrigerator]  <b>(181)</b> [taken]  <b>(182)</b> [glass]  <b>(183)</b> [egg]  <b>(184)</b> [growing]  <b>(185)</b> [ledge]  <b>(186)</b> [clock]  <b>(187)</b> [catching]  <b>(188)</b> [snowboard]  <b>(189)</b> [child]  <b>(190)</b> [electric]  <b>(191)</b> [say]  <b>(192)</b> [lie]  <b>(193)</b> [pan]  <b>(194)</b> [book]  <b>(195)</b> [grazing]  <b>(196)</b> [chocolate]  <b>(197)</b> [bean]  <b>(198)</b> [chef]  <b>(199)</b> [handle]  <b>(200)</b> [professional]  <b>(201)</b> [pointing]  <b>(202)</b> [make]  <b>(203)</b> [taking]  <b>(204)</b> [appears]  <b>(205)</b> [slice]  <b>(206)</b> [structure]  <b>(207)</b> [cute]  <b>(208)</b> [screen]  <b>(209)</b> [go]  <b>(210)</b> [motorcyclist]  <b>(211)</b> [take]  <b>(212)</b> [style]  <b>(213)</b> [controller]  <b>(214)</b> [airplane]  <b>(215)</b> [wrapped]  <b>(216)</b> [back]  <b>(217)</b> [stunt]  <b>(218)</b> [potato]  <b>(219)</b> [moving]  <b>(220)</b> [onto]  <b>(221)</b> [three]  <b>(222)</b> [neatly]  <b>(223)</b> [cattle]  <b>(224)</b> [driver]  <b>(225)</b> [beside]  <b>(226)</b> [disc]  <b>(227)</b> [doughnut]  <b>(228)</b> [seagull]  <b>(229)</b> [move]  <b>(230)</b> [sleeping]  <b>(231)</b> [nearby]  <b>(232)</b> [toothbrush]  <b>(233)</b> [apple]  <b>(234)</b> [lid]  <b>(235)</b> [bedroom]  <b>(236)</b> [boarding]  <b>(237)</b> [dirt]  <b>(238)</b> [tiled]  <b>(239)</b> [touching]  <b>(240)</b> [wild]  <b>(241)</b> [doorway]  <b>(242)</b> [holder]  <b>(243)</b> [bar]  <b>(244)</b> [cover]  <b>(245)</b> [fried]  <b>(246)</b> [cloudy]  <b>(247)</b> [mitt]  <b>(248)</b> [dock]  <b>(249)</b> [pizza]  <b>(250)</b> [toilet]  <b>(251)</b> [travel]  <b>(252)</b> [giraffe]  <b>(253)</b> [skateboard]  <b>(254)</b> [topping]  <b>(255)</b> [writing]  <b>(256)</b> [shelf]  <b>(257)</b> [runway]  <b>(258)</b> [jacket]  <b>(259)</b> [ketchup]  <b>(260)</b> [close-up]  <b>(261)</b> [water]  <b>(262)</b> [shoulder]  <b>(263)</b> [foreground]  <b>(264)</b> [knife]  <b>(265)</b> [kitten]  <b>(266)</b> [metal]  <b>(267)</b> [track]  <b>(268)</b> [reading]  <b>(269)</b> [shower]  <b>(270)</b> [carry]  <b>(271)</b> [candle]  <b>(272)</b> [flying]  <b>(273)</b> [pant]  <b>(274)</b> [yellow]  <b>(275)</b> [kneeling]  <b>(276)</b> [spoon]  <b>(277)</b> [paved]  <b>(278)</b> [using]  <b>(279)</b> [sausage]  <b>(280)</b> [relaxing]  <b>(281)</b> [empty]  <b>(282)</b> [resting]  <b>(283)</b> [pink]  <b>(284)</b> [walking]  <b>(285)</b> [bag]  <b>(286)</b> [pepper]  <b>(287)</b> [grass]  <b>(288)</b> [broccoli]  <b>(289)</b> [silver]  <b>(290)</b> [stop]  <b>(291)</b> [helmet]  <b>(292)</b> [stuffed]  <b>(293)</b> [pavement]  <b>(294)</b> [tree]  <b>(295)</b> [front]  <b>(296)</b> [gather]  <b>(297)</b> [outdoor]  <b>(298)</b> [race]  <b>(299)</b> [photograph]  <b>(300)</b> [cake]  <b>(301)</b> [game]  <b>(302)</b> [landing]  <b>(303)</b> [dry]  <b>(304)</b> [control]  <b>(305)</b> [lawn]  <b>(306)</b> [stone]  <b>(307)</b> [church]  <b>(308)</b> [strawberry]  <b>(309)</b> [officer]  <b>(310)</b> [airport]  <b>(311)</b> [sailing]  <b>(312)</b> [doe]  <b>(313)</b> [six]  <b>(314)</b> [plain]  <b>(315)</b> [place]  <b>(316)</b> [light]  <b>(317)</b> [giving]  <b>(318)</b> [milk]  <b>(319)</b> [fruit]  <b>(320)</b> [short]  <b>(321)</b> [frosting]  <b>(322)</b> [roll]  <b>(323)</b> [sliding]  <b>(324)</b> [outdoors]  <b>(325)</b> [pitch]  <b>(326)</b> [grill]  <b>(327)</b> [riding]  <b>(328)</b> [supply]  <b>(329)</b> [traveling]  <b>(330)</b> [motor]  <b>(331)</b> [shop]  <b>(332)</b> [served]  <b>(333)</b> [pull]  <b>(334)</b> [carriage]  <b>(335)</b> [gas]  <b>(336)</b> [play]  <b>(337)</b> [swing]  <b>(338)</b> [trail]  <b>(339)</b> [living]  <b>(340)</b> [dresser]  <b>(341)</b> [racing]  <b>(342)</b> [bite]  <b>(343)</b> [spectator]  <b>(344)</b> [perched]  <b>(345)</b> [loaded]  <b>(346)</b> [salad]  <b>(347)</b> [food]  <b>(348)</b> [table]  <b>(349)</b> [rainy]  <b>(350)</b> [city]  <b>(351)</b> [boat]  <b>(352)</b> [tow]  <b>(353)</b> [enjoying]  <b>(354)</b> [olive]  <b>(355)</b> [carpet]  <b>(356)</b> [couple]  <b>(357)</b> [surfing]  <b>(358)</b> [tray]  <b>(359)</b> [elderly]  <b>(360)</b> [nintendo]  <b>(361)</b> [coffee]  <b>(362)</b> [dressed]  <b>(363)</b> [car]  <b>(364)</b> [drink]  <b>(365)</b> [spread]  <b>(366)</b> [pose]  <b>(367)</b> [seated]  <b>(368)</b> [pickle]  <b>(369)</b> [shopping]  <b>(370)</b> [dining]  <b>(371)</b> [crossing]  <b>(372)</b> [sign]  <b>(373)</b> [eat]  <b>(374)</b> [pulling]  <b>(375)</b> [wheel]  <b>(376)</b> [beach]  <b>(377)</b> [worker]  <b>(378)</b> [fake]  <b>(379)</b> [paddle]  <b>(380)</b> [placed]  <b>(381)</b> [eats]  <b>(382)</b> [doll]  <b>(383)</b> [lap]  <b>(384)</b> [lush]  <b>(385)</b> [harbor]  <b>(386)</b> [zebra]  <b>(387)</b> [thing]  <b>(388)</b> [sweater]  <b>(389)</b> [sit]  <b>(390)</b> [snowboarder]  <b>(391)</b> [show]  <b>(392)</b> [duck]  <b>(393)</b> [four]  <b>(394)</b> [basket]  <b>(395)</b> [rain]  <b>(396)</b> [row]  <b>(397)</b> [indoor]  <b>(398)</b> [store]  <b>(399)</b> [statue]  <b>(400)</b> [vehicle]  <b>(401)</b> [female]  <b>(402)</b> [colored]  <b>(403)</b> [tooth]  <b>(404)</b> [cutting]  <b>(405)</b> [commercial]  <b>(406)</b> [dog]  <b>(407)</b> [giant]  <b>(408)</b> [public]  <b>(409)</b> [decker]  <b>(410)</b> [shirtless]  <b>(411)</b> [skate]  <b>(412)</b> [jean]  <b>(413)</b> [flock]  <b>(414)</b> [stair]  <b>(415)</b> [tied]  <b>(416)</b> [step]  <b>(417)</b> [paw]  <b>(418)</b> [mouse]  <b>(419)</b> [jump]  <b>(420)</b> [steel]  <b>(421)</b> [cat]  <b>(422)</b> [desk]  <b>(423)</b> [feeding]  <b>(424)</b> [flower]  <b>(425)</b> [design]  <b>(426)</b> [flip]  <b>(427)</b> [modern]  <b>(428)</b> [adult]  <b>(429)</b> [someone]  <b>(430)</b> [wet]  <b>(431)</b> [log]  <b>(432)</b> [wind]  <b>(433)</b> [toddler]  <b>(434)</b> [shore]  <b>(435)</b> [hitting]  <b>(436)</b> [slope]  <b>(437)</b> [island]  <b>(438)</b> [decorative]  <b>(439)</b> [cup]  <b>(440)</b> [pasta]  <b>(441)</b> [enclosed]  <b>(442)</b> [soccer]  <b>(443)</b> [animal]  <b>(444)</b> [air]  <b>(445)</b> [carrot]  <b>(446)</b> [palm]  <b>(447)</b> [getting]  <b>(448)</b> [pillow]  <b>(449)</b> [leaf]  <b>(450)</b> [laid]  <b>(451)</b> [wooden]  <b>(452)</b> [attempting]  <b>(453)</b> [rolling]  <b>(454)</b> [color]  <b>(455)</b> [highway]  <b>(456)</b> [sill]  <b>(457)</b> [rest]  <b>(458)</b> [narrow]  <b>(459)</b> [branch]  <b>(460)</b> [filled]  <b>(461)</b> [lady]  <b>(462)</b> [smile]  <b>(463)</b> [foot]  <b>(464)</b> [appliance]  <b>(465)</b> [sheep]  <b>(466)</b> [sandwich]  <b>(467)</b> [deck]  <b>(468)</b> [written]  <b>(469)</b> [fork]  <b>(470)</b> [christmas]  <b>(471)</b> [match]  <b>(472)</b> [kite]  <b>(473)</b> [aircraft]  <b>(474)</b> [cabinet]  <b>(475)</b> [cooked]  <b>(476)</b> [lamp]  <b>(477)</b> [rail]  <b>(478)</b> [grey]  <b>(479)</b> [corner]  <b>(480)</b> [playing]  <b>(481)</b> [sunglass]  <b>(482)</b> [sofa]  <b>(483)</b> [towards]  <b>(484)</b> [end]  <b>(485)</b> [orange]  <b>(486)</b> [huge]  <b>(487)</b> [purple]  <b>(488)</b> [working]  <b>(489)</b> [pastry]  <b>(490)</b> [cart]  <b>(491)</b> [van]  <b>(492)</b> [vas]  <b>(493)</b> [talking]  <b>(494)</b> [cream]  <b>(495)</b> [painted]  <b>(496)</b> [display]  <b>(497)</b> [dinner]  <b>(498)</b> [closed]  <b>(499)</b> [turn]  <b>(500)</b> [fireplace]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Unknown label-space</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>(1)</b> [inside]  <b>(2)</b> [bottle]  <b>(3)</b> [flag]  <b>(4)</b> [railing]  <b>(5)</b> [backpack]  <b>(6)</b> [toast]  <b>(7)</b> [containing]  <b>(8)</b> [square]  <b>(9)</b> [model]  <b>(10)</b> [passing]  <b>(11)</b> [pond]  <b>(12)</b> [ball]  <b>(13)</b> [attached]  <b>(14)</b> [painting]  <b>(15)</b> [beneath]  <b>(16)</b> [flight]  <b>(17)</b> [gathered]  <b>(18)</b> [laptop]  <b>(19)</b> [lit]  <b>(20)</b> [house]  <b>(21)</b> [outside]  <b>(22)</b> [shoe]  <b>(23)</b> [tent]  <b>(24)</b> [polar]  <b>(25)</b> [scene]  <b>(26)</b> [racquet]  <b>(27)</b> [arm]  <b>(28)</b> [shirt]  <b>(29)</b> [couch]  <b>(30)</b> [room]  <b>(31)</b> [driving]  <b>(32)</b> [long]  <b>(33)</b> [fish]  <b>(34)</b> [cupcake]  <b>(35)</b> [wa]  <b>(36)</b> [dish]  <b>(37)</b> [lying]  <b>(38)</b> [looking]  <b>(39)</b> [ready]  <b>(40)</b> [reflection]  <b>(41)</b> [shown]  <b>(42)</b> [skateboarding]  <b>(43)</b> [antique]  <b>(44)</b> [holding]  <b>(45)</b> [baseball]  <b>(46)</b> [shape]  <b>(47)</b> [shot]  <b>(48)</b> [top]  <b>(49)</b> [cow]  <b>(50)</b> [lined]  <b>(51)</b> [sunset]  <b>(52)</b> [lemon]  <b>(53)</b> [cheese]  <b>(54)</b> [beige]  <b>(55)</b> [clothes]  <b>(56)</b> [bush]  <b>(57)</b> [ship]  <b>(58)</b> [tub]  <b>(59)</b> [sleep]  <b>(60)</b> [dirty]  <b>(61)</b> [trailer]  <b>(62)</b> [rear]  <b>(63)</b> [point]  <b>(64)</b> [mountain]  <b>(65)</b> [number]  <b>(66)</b> [falling]  <b>(67)</b> [wagon]  <b>(68)</b> [body]  <b>(69)</b> [concrete]  <b>(70)</b> [assorted]  <b>(71)</b> [soup]  <b>(72)</b> [camera]  <b>(73)</b> [post]  <b>(74)</b> [bathroom]  <b>(75)</b> [urban]  <b>(76)</b> [older]  <b>(77)</b> [prepares]  <b>(78)</b> [parking]  <b>(79)</b> [hang]  <b>(80)</b> [sculpture]  <b>(81)</b> [plate]  <b>(82)</b> [tall]  <b>(83)</b> [guy]  <b>(84)</b> [winter]  <b>(85)</b> [one]  <b>(86)</b> [lean]  <b>(87)</b> [tv]  <b>(88)</b> [cross]  <b>(89)</b> [rock]  <b>(90)</b> [wait]  <b>(91)</b> [upside]  <b>(92)</b> [bike]  <b>(93)</b> [eating]  <b>(94)</b> [railroad]  <b>(95)</b> [bath]  <b>(96)</b> [throw]  <b>(97)</b> [ramp]  <b>(98)</b> [bed]  <b>(99)</b> [propeller]  <b>(100)</b> [seat]  <b>(101)</b> [commuter]  <b>(102)</b> [setting]  <b>(103)</b> [collection]  <b>(104)</b> [two]  <b>(105)</b> [picture]  <b>(106)</b> [onion]  <b>(107)</b> [uniform]  <b>(108)</b> [eye]  <b>(109)</b> [puppy]  <b>(110)</b> [pipe]  <b>(111)</b> [ocean]  <b>(112)</b> [another]  <b>(113)</b> [eaten]  <b>(114)</b> [single]  <b>(115)</b> [luggage]  <b>(116)</b> [full]  <b>(117)</b> [fan]  <b>(118)</b> [surrounded]  <b>(119)</b> [pasture]  <b>(120)</b> [school]  <b>(121)</b> [cut]  <b>(122)</b> [watch]  <b>(123)</b> [player]  <b>(124)</b> [past]  <b>(125)</b> [country]  <b>(126)</b> [fire]  <b>(127)</b> [cement]  <b>(128)</b> [young]  <b>(129)</b> [clothing]  <b>(130)</b> [part]  <b>(131)</b> [alone]  <b>(132)</b> [sized]  <b>(133)</b> [noodle]  <b>(134)</b> [deep]  <b>(135)</b> [business]  <b>(136)</b> [wine]  <b>(137)</b> [preparing]  <b>(138)</b> [path]  <b>(139)</b> [posing]  <b>(140)</b> [rose]  <b>(141)</b> [tarmac]  <b>(142)</b> [hand]  <b>(143)</b> [garden]  <b>(144)</b> [paper]  <b>(145)</b> [pole]  <b>(146)</b> [floating]  <b>(147)</b> [gray]  <b>(148)</b> [window]  <b>(149)</b> [curb]  <b>(150)</b> [tool]  <b>(151)</b> [ski]  <b>(152)</b> [fenced]  <b>(153)</b> [lone]  <b>(154)</b> [rope]  <b>(155)</b> [parked]  <b>(156)</b> [suitcase]  <b>(157)</b> [garage]  <b>(158)</b> [wii]  <b>(159)</b> [electronic]  <b>(160)</b> [docked]  <b>(161)</b> [dress]  <b>(162)</b> [running]  <b>(163)</b> [catcher]  <b>(164)</b> [tie]  <b>(165)</b> [messy]  <b>(166)</b> [mouth]  <b>(167)</b> [pool]  <b>(168)</b> [home]  <b>(169)</b> [different]  <b>(170)</b> [pie]  <b>(171)</b> [blanket]  <b>(172)</b> [along]  <b>(173)</b> [stick]  <b>(174)</b> [stopped]  <b>(175)</b> [hat]  <b>(176)</b> [hanging]  <b>(177)</b> [bright]  <b>(178)</b> [phone]  <b>(179)</b> [produce]  <b>(180)</b> [utensil]  <b>(181)</b> [paint]  <b>(182)</b> [beverage]  <b>(183)</b> [birthday]  <b>(184)</b> [serving]  <b>(185)</b> [tile]  <b>(186)</b> [station]  <b>(187)</b> [talk]  <b>(188)</b> [drive]  <b>(189)</b> [right]  <b>(190)</b> [crowd]  <b>(191)</b> [atop]  <b>(192)</b> [desktop]  <b>(193)</b> [roadway]  <b>(194)</b> [wire]  <b>(195)</b> [scooter]  <b>(196)</b> [underneath]  <b>(197)</b> [read]  <b>(198)</b> [stuff]  <b>(199)</b> [trick]  <b>(200)</b> [fly]  <b>(201)</b> [sea]  <b>(202)</b> [wood]  <b>(203)</b> [dessert]  <b>(204)</b> [park]  <b>(205)</b> [behind]  <b>(206)</b> [overhead]  <b>(207)</b> [arranged]  <b>(208)</b> [word]  <b>(209)</b> [night]  <b>(210)</b> [meter]  <b>(211)</b> [fresh]  <b>(212)</b> [bridge]  <b>(213)</b> [computer]  <b>(214)</b> [meat]  <b>(215)</b> [approaching]  <b>(216)</b> [desert]  <b>(217)</b> [wave]  <b>(218)</b> [wooded]  <b>(219)</b> [individual]  <b>(220)</b> [tea]  <b>(221)</b> [held]  <b>(222)</b> [loading]  <b>(223)</b> [case]  <b>(224)</b> [traffic]  <b>(225)</b> [type]  <b>(226)</b> [stainless]  <b>(227)</b> [cloth]  <b>(228)</b> [performs]  <b>(229)</b> [vegetable]  <b>(230)</b> [train]  <b>(231)</b> [set]  <b>(232)</b> [vanity]  <b>(233)</b> [ceiling]  <b>(234)</b> [swinging]  <b>(235)</b> [fighter]  <b>(236)</b> [passenger]  <b>(237)</b> [telephone]  <b>(238)</b> [left]  <b>(239)</b> [close]  <b>(240)</b> [gold]  <b>(241)</b> [chain]  <b>(242)</b> [umbrella]  <b>(243)</b> [rural]  <b>(244)</b> [piece]  <b>(245)</b> [bowl]  <b>(246)</b> [away]  <b>(247)</b> [kind]  <b>(248)</b> [put]  <b>(249)</b> [hillside]  <b>(250)</b> [open]  <b>(251)</b> [town]  <b>(252)</b> [use]  <b>(253)</b> [hit]  <b>(254)</b> [surfboard]  <b>(255)</b> [alongside]  <b>(256)</b> [beer]  <b>(257)</b> [plant]  <b>(258)</b> [plastic]  <b>(259)</b> [chip]  <b>(260)</b> [reaching]  <b>(261)</b> [includes]  <b>(262)</b> [leg]  <b>(263)</b> [colorful]  <b>(264)</b> [gear]  <b>(265)</b> [bacon]  <b>(266)</b> [soda]  <b>(267)</b> [engine]  <b>(268)</b> [tank]  <b>(269)</b> [``]  <b>(270)</b> [us]  <b>(271)</b> [tower]  <b>(272)</b> [bus]  <b>(273)</b> [jar]  <b>(274)</b> [stall]  <b>(275)</b> [see]  <b>(276)</b> [wide]  <b>(277)</b> [round]  <b>(278)</b> [jumping]  <b>(279)</b> [teeth]  <b>(280)</b> [intersection]  <b>(281)</b> [microwave]  <b>(282)</b> [field]  <b>(283)</b> [mirror]  <b>(284)</b> [fridge]  <b>(285)</b> [catch]  <b>(286)</b> [rack]  <b>(287)</b> [fry]  <b>(288)</b> [market]  <b>(289)</b> [used]  <b>(290)</b> [showing]  <b>(291)</b> [center]  <b>(292)</b> [sticking]  <b>(293)</b> [boarder]  <b>(294)</b> [blurry]  <b>(295)</b> [wearing]  <b>(296)</b> [tiny]  <b>(297)</b> [goat]  <b>(298)</b> [baby]  <b>(299)</b> [line]  <b>(300)</b> [machine]  <b>(301)</b> [building]  <b>(302)</b> [leading]  <b>(303)</b> [american]  <b>(304)</b> [mug]  <b>(305)</b> [facing]  <b>(306)</b> [bathtub]  <b>(307)</b> [area]  <b>(308)</b> [construction]  <b>(309)</b> [mounted]  <b>(310)</b> [bicycle]  <b>(311)</b> [roof]  <b>(312)</b> [half]  <b>(313)</b> [assortment]  <b>(314)</b> [base]  <b>(315)</b> [snack]  <b>(316)</b> [throwing]  <b>(317)</b> [monitor]  <b>(318)</b> [carrying]  <b>(319)</b> [frame]  <b>(320)</b> [men]  <b>(321)</b> [pot]  <b>(322)</b> [pass]  <b>(323)</b> [ride]  <b>(324)</b> [double]  <b>(325)</b> [glove]  <b>(326)</b> [bread]  <b>(327)</b> [near]  <b>(328)</b> [middle]  <b>(329)</b> [pen]  <b>(330)</b> [string]  <b>(331)</b> [outfit]  <b>(332)</b> [friend]  <b>(333)</b> [stool]  <b>(334)</b> [green]  <b>(335)</b> [walkway]  <b>(336)</b> [edge]  <b>(337)</b> [sale]  <b>(338)</b> [cellphone]  <b>(339)</b> [low]  <b>(340)</b> [device]  <b>(341)</b> [staring]  <b>(342)</b> [apartment]  <b>(343)</b> [nice]  <b>(344)</b> [toy]  <b>(345)</b> [ground]  <b>(346)</b> [umpire]  <b>(347)</b> [boy]  <b>(348)</b> [team]  <b>(349)</b> [office]  <b>(350)</b> [elephant]  <b>(351)</b> [bucket]  <b>(352)</b> [barn]  <b>(353)</b> [blue]  <b>(354)</b> [smiling]  <b>(355)</b> [airliner]  <b>(356)</b> [still]  <b>(357)</b> [shade]  <b>(358)</b> [next]  <b>(359)</b> [laying]  <b>(360)</b> [across]  <b>(361)</b> [meal]  <b>(362)</b> [turned]  <b>(363)</b> [floor]  <b>(364)</b> [others]  <b>(365)</b> [banana]  <b>(366)</b> [enclosure]  <b>(367)</b> [beautiful]  <b>(368)</b> [performing]  <b>(369)</b> [teddy]  <b>(370)</b> [displayed]  <b>(371)</b> [rice]  <b>(372)</b> [little]  <b>(373)</b> [trash]  <b>(374)</b> [side]  <b>(375)</b> [good]  <b>(376)</b> [smart]  <b>(377)</b> [cloud]  <b>(378)</b> [wedding]  <b>(379)</b> [various]  <b>(380)</b> [built]  <b>(381)</b> [leather]  <b>(382)</b> [curtain]  <b>(383)</b> [toward]  <b>(384)</b> [opened]  <b>(385)</b> [batter]  <b>(386)</b> [pepperoni]  <b>(387)</b> [cap]  <b>(388)</b> [bow]  <b>(389)</b> [restroom]  <b>(390)</b> [guitar]  <b>(391)</b> [people]  <b>(392)</b> [large]  <b>(393)</b> [sailboat]  <b>(394)</b> [old]  <b>(395)</b> [stand]  <b>(396)</b> [coming]  <b>(397)</b> [item]  <b>(398)</b> [blender]  <b>(399)</b> [space]  <b>(400)</b> [restaurant]  <b>(401)</b> [brush]  <b>(402)</b> [around]  <b>(403)</b> [subway]  <b>(404)</b> [steam]  <b>(405)</b> [locomotive]  <b>(406)</b> [ornate]  <b>(407)</b> [siting]  <b>(408)</b> [residential]  <b>(409)</b> [urinal]  <b>(410)</b> [brown]  <b>(411)</b> [rocky]  <b>(412)</b> [fence]  <b>(413)</b> [drawn]  <b>(414)</b> [leash]  <b>(415)</b> [board]  <b>(416)</b> [displaying]  <b>(417)</b> [land]  <b>(418)</b> [patio]  <b>(419)</b> [wear]  <b>(420)</b> [fancy]  <b>(421)</b> [well]  <b>(422)</b> [reach]  <b>(423)</b> [veggie]  <b>(424)</b> [military]  <b>(425)</b> [gate]  <b>(426)</b> [costume]  <b>(427)</b> [hill]  <b>(428)</b> [busy]  <b>(429)</b> [sport]  <b>(430)</b> [together]  <b>(431)</b> [new]  <b>(432)</b> [leaning]  <b>(433)</b> [dark]  <b>(434)</b> [many]  <b>(435)</b> [ripe]  <b>(436)</b> [red]  <b>(437)</b> [head]  <b>(438)</b> [video]  <b>(439)</b> [lift]  <b>(440)</b> [road]  <b>(441)</b> [image]  <b>(442)</b> [view]  <b>(443)</b> [power]  <b>(444)</b> [bun]  <b>(445)</b> [background]  <b>(446)</b> [bear]  <b>(447)</b> [crowded]  <b>(448)</b> [sun]  <b>(449)</b> [like]  <b>(450)</b> [net]  <b>(451)</b> [yard]  <b>(452)</b> [parade]  <b>(453)</b> [brick]  <b>(454)</b> [cone]  <b>(455)</b> [smaller]  <b>(456)</b> [pet]  <b>(457)</b> [multiple]  <b>(458)</b> [group]  <b>(459)</b> [making]  <b>(460)</b> [overlooking]  <b>(461)</b> [covered]  <b>(462)</b> [surf]  <b>(463)</b> [neck]  <b>(464)</b> [distance]  <b>(465)</b> [sand]  <b>(466)</b> [sheet]  <b>(467)</b> [going]  <b>(468)</b> [stack]  <b>(469)</b> [transit]  <b>(470)</b> [bird]  <b>(471)</b> [door]  <b>(472)</b> [zoo]  <b>(473)</b> [picnic]  <b>(474)</b> [kid]  <b>(475)</b> [crosswalk]  <b>(476)</b> [happy]  <b>(477)</b> [grassy]  <b>(478)</b> [herd]  <b>(479)</b> [action]  <b>(480)</b> [sink]  <b>(481)</b> [skating]  <b>(482)</b> [tan]  <b>(483)</b> [pair]  <b>(484)</b> [tomato]  <b>(485)</b> [bench]  <b>(486)</b> [court]  <b>(487)</b> [feature]  <b>(488)</b> [formation]  <b>(489)</b> [snowboarding]  <b>(490)</b> [shaped]  <b>(491)</b> [hotel]  <b>(492)</b> [pier]  <b>(493)</b> [mother]  <b>(494)</b> [asian]  <b>(495)</b> [sitting]  <b>(496)</b> [museum]  <b>(497)</b> [hotdog]  <b>(498)</b> [rider]  <b>(499)</b> [rug]  <b>(500)</b> [snow]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def random_split_labelspace(data, numKnownLabels = 40):\n",
    "    random_seq = np.random.permutation(data.numCategories())\n",
    "    # We know the first K labels.\n",
    "    knownLabels = [data.vocabulary[1].keys()[idx] for idx in random_seq[:numKnownLabels]]\n",
    "    knownLabelIds = [data.word2id(word) for word in knownLabels]\n",
    "\n",
    "    # We don't know the other labels.\n",
    "    unknownLabels = [data.vocabulary[1].keys()[idx] for idx in random_seq[numKnownLabels:]]\n",
    "    unknownLabelIds = [data.word2id(word) for word in unknownLabels]\n",
    "    return knownLabels, knownLabelIds, unknownLabels, unknownLabelIds\n",
    "\n",
    "label_space_split_file = 'coco_label_split500.p'\n",
    "\n",
    "if not os.path.exists(label_space_split_file):\n",
    "    knownLabels, knownLabelIds, unknownLabels, unknownLabelIds = random_split_labelspace(valData, 500)\n",
    "    torch.save({'knownLabelIds': knownLabelIds, 'unknownLabelIds': unknownLabelIds,\n",
    "                'knownLabels': knownLabels, 'unknownLabels': unknownLabels},\n",
    "                open(label_space_split_file, 'w'))\n",
    "else:\n",
    "    space = torch.load(open(label_space_split_file))\n",
    "    knownLabelIds = space['knownLabelIds']\n",
    "    unknownLabelIds = space['unknownLabelIds']\n",
    "    knownLabels = space['knownLabels']\n",
    "    unknownLabels = space['unknownLabels']\n",
    "# Show the two groups.\n",
    "labelspace = ['<b>(%d)</b> [%s]' % (i + 1, label) for (i, label) in enumerate(knownLabels)]\n",
    "labelspace = string.join(labelspace, '  ')\n",
    "display(HTML('<h3>Known label-space</h3>'))\n",
    "display(HTML(labelspace))\n",
    "\n",
    "labelspace = ['<b>(%d)</b> [%s]' % (i + 1, label) for (i, label) in enumerate(unknownLabels)]\n",
    "labelspace = string.join(labelspace, '  ')\n",
    "display(HTML('<h3>Unknown label-space</h3>'))\n",
    "display(HTML(labelspace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer-wise Feedback-prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LF(nn.Module):\n",
    "\n",
    "    def __init__(self, n_categories):\n",
    "        super(LF, self).__init__()\n",
    "       \n",
    "        self.n_categories = n_categories\n",
    "        self.base_network = models.resnet18(pretrained = True)\n",
    "        \n",
    "        self.base_network.fc = nn.Conv2d(512, n_categories, 1)\n",
    "        \n",
    "        self.layers = [\n",
    "            ('input_image', lambda x:x),\n",
    "            ('conv1', lambda x: self.base_network.conv1(x)),\n",
    "            ('conv5', lambda x: self.base_network.layer1(self.base_network.maxpool(\n",
    "                self.base_network.relu(self.base_network.bn1(x))))),\n",
    "            ('conv9',  lambda x: self.base_network.layer2(x)),\n",
    "            ('conv13', lambda x: self.base_network.layer3(x)),\n",
    "            ('conv17', lambda x: self.base_network.layer4(x)),\n",
    "            ('fc', lambda x: self.base_network.fc(x)),\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for name, operator in self.layers:\n",
    "            x = operator(x)\n",
    "            setattr(self, name, x)\n",
    "        # Take the max for each prediction map.\n",
    "        return x.max(dim = 2, keepdim=True)[0].max(dim = 3, keepdim=True)[0].squeeze()\n",
    "    \n",
    "    def partial_forward(self, start):\n",
    "        skip = True\n",
    "        for name, operator in self.layers:\n",
    "            if name == start:\n",
    "                x = getattr(self, name)\n",
    "                skip = False\n",
    "            elif skip:\n",
    "                continue\n",
    "            else:\n",
    "                x = operator(x)\n",
    "                setattr(self, name, x)\n",
    "\n",
    "        return x.max(dim = 2, keepdim=True)[0].max(dim = 3, keepdim=True)[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint (epoch 41)\n"
     ]
    }
   ],
   "source": [
    "# Prepare model.\n",
    "LF_model = LF(1000)\n",
    "LF_model = nn.DataParallel(LF_model).cuda()\n",
    "checkpoint = torch.load(os.path.join(args.logDir, 'model_best.pth.tar'))\n",
    "args.startEpoch = checkpoint['epoch']\n",
    "best_error = checkpoint['error']\n",
    "LF_model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"=> loaded checkpoint (epoch {})\".format(checkpoint['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feedback_prop_lf_val(net, knownLabelIds, unknownLabelIds, layers=['input_a'], num_iterations=20, lr=1e-3):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = defaultdict(list)\n",
    "    t = tqdm(valLoader, desc=\"Evaluating on Val:\")\n",
    "    t_knownLabelIds   = torch.LongTensor(knownLabelIds).cuda()\n",
    "    t_unknownLabelIds = torch.LongTensor(unknownLabelIds).cuda()\n",
    "    \n",
    "    for batch_idx, (data, target, imageIds) in enumerate(t):\n",
    "        # Prepare inputs.\n",
    "#         if batch_idx == 10: break\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # Inference.\n",
    "        output = net(data)\n",
    "        # Check the performance of known and unknown subsets\n",
    "        knownLabelPredictions = output.index_select(1, Variable(t_knownLabelIds))\n",
    "        knownLabelValues = target.index_select(1, Variable(t_knownLabelIds))\n",
    "        unknownLabelPredictions = output.index_select(1, Variable(t_unknownLabelIds))\n",
    "        unknownLabelValues = target.index_select(1, Variable(t_unknownLabelIds))\n",
    "        \n",
    "        for layer in layers:\n",
    "            activation = Variable(getattr(net.module, layer).data, requires_grad=True)\n",
    "            setattr(net.module, layer, activation)\n",
    "            \n",
    "            optimizer = optim.Adam([activation], lr = lr, weight_decay = 1e-4)\n",
    "            for iteration in range(0, num_iterations):\n",
    "                output = net.module.partial_forward(layer)\n",
    "                knownLabelPredictions = output.index_select(1, Variable(t_knownLabelIds))\n",
    "                loss = F.binary_cross_entropy_with_logits(knownLabelPredictions, knownLabelValues)\n",
    "                optimizer.zero_grad()  \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if layer == layers[-1]:\n",
    "                    results[iteration].append((imageIds, output.data.cpu(), target.data.cpu()))\n",
    "            output = net.module.partial_forward(layer)\n",
    "            if layer == layers[-1]:\n",
    "                results[iteration + 1].append((imageIds, output.data.cpu(), target.data.cpu()))\n",
    "            activation.requires_grad = False  # Freeze this layer.\n",
    "\n",
    "        # Logging information.\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += torch.gather(target.data, 1, pred).cpu().sum()\n",
    "        t.set_postfix(correct = str(correct))\n",
    "    \n",
    "    predictions = dict()\n",
    "    for iteration in results.keys():\n",
    "        predictions[iteration] = torch.cat([entry[1] for entry in results[iteration]], 0)\n",
    "    targets = torch.cat([entry[2] for entry in results[0]], 0)\n",
    "    \n",
    "    meanAP_unknown = list()\n",
    "    meanAP_known = list()\n",
    "    unknown_targets = targets.index_select(1, torch.LongTensor(unknownLabelIds)).numpy()\n",
    "    known_targets = targets.index_select(1, torch.LongTensor(knownLabelIds)).numpy()\n",
    "    for iteration in range(len(results)):\n",
    "        meanAP_unknown.append(100 * ( average_precision_score(unknown_targets,\n",
    "            (predictions[iteration] + 1e-5).index_select(1, torch.LongTensor(unknownLabelIds)).numpy(), average='macro')))\n",
    "        meanAP_known.append(100 * ( average_precision_score(known_targets,\n",
    "            (predictions[iteration] + 1e-5).index_select(1, torch.LongTensor(knownLabelIds)).numpy(), average='macro')))\n",
    "\n",
    "    \n",
    "    return meanAP_unknown, meanAP_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad29d271017442e9b120ca3de7e137c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of iteration for max meanAP:', 10)\n"
     ]
    }
   ],
   "source": [
    "meanAP_unknown, meanAP_known = feedback_prop_lf_val(\n",
    "    LF_model, knownLabelIds, unknownLabelIds, layers=['conv13'], num_iterations=20, lr=3e-3)\n",
    "print(\"number of iteration for max meanAP:\", np.argmax(np.asarray(meanAP_unknown)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f13406018d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13408063d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13469bae50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'meanAP': meanAP_unknown}, index = range(0, 21))\n",
    "df.index.name = \"epochs\"\n",
    "plt.figure()\n",
    "df.plot(title=' '.join('conv13'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune parameters(learning_rate and num_iterations) on val set and apply on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feedback_prop_lf_test(net, knownLabelIds, unknownLabelIds, layers=['input_a'], num_iterations=20, lr=1e-3):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = list()\n",
    "    t = tqdm(testLoader, desc=\"Evaluating on Test:\")\n",
    "    t_knownLabelIds   = torch.LongTensor(knownLabelIds).cuda()\n",
    "    t_unknownLabelIds = torch.LongTensor(unknownLabelIds).cuda()\n",
    "    \n",
    "    for batch_idx, (data, target, imageIds) in enumerate(t):\n",
    "        # Prepare inputs.\n",
    "#         if batch_idx == 3: break\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # Inference.\n",
    "        output = net(data)\n",
    "        # Check the performance of known and unknown subsets\n",
    "        knownLabelPredictions = output.index_select(1, Variable(t_knownLabelIds))\n",
    "        knownLabelValues = target.index_select(1, Variable(t_knownLabelIds))\n",
    "        unknownLabelPredictions = output.index_select(1, Variable(t_unknownLabelIds))\n",
    "        unknownLabelValues = target.index_select(1, Variable(t_unknownLabelIds))\n",
    "        \n",
    "        for layer in layers:\n",
    "            activation = Variable(getattr(net.module, layer).data, requires_grad=True)\n",
    "            setattr(net.module, layer, activation)\n",
    "            \n",
    "            optimizer = optim.Adam([activation], lr = lr, weight_decay = 1e-4)\n",
    "            for iteration in range(0, num_iterations):\n",
    "                output = net.module.partial_forward(layer)\n",
    "                knownLabelPredictions = output.index_select(1, Variable(t_knownLabelIds))\n",
    "                loss = F.binary_cross_entropy_with_logits(knownLabelPredictions, knownLabelValues)\n",
    "                optimizer.zero_grad()  \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            output = net.module.partial_forward(layer)\n",
    "            activation.requires_grad = False  # Freeze this layer.\n",
    "\n",
    "        # Logging information.\n",
    "        results.append((imageIds, output.data.cpu(), target.data.cpu(), unknownLabelPredictions.data.cpu()))\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += torch.gather(target.data, 1, pred).cpu().sum()\n",
    "        t.set_postfix(correct = str(correct))\n",
    "    \n",
    "    predictions = torch.cat([entry[1] for entry in results], 0)\n",
    "    targets = torch.cat([entry[2] for entry in results], 0)\n",
    "    ori_predictions = torch.cat([entry[3] for entry in results], 0)\n",
    "    old_meanAP = 100 * (average_precision_score(targets.index_select(1, torch.LongTensor(unknownLabelIds)).numpy(),\n",
    "                                     (ori_predictions + 1e-5).numpy(),\n",
    "                                    average = 'macro'))\n",
    "    new_meanAP = 100 * (average_precision_score(targets.index_select(1, torch.LongTensor(unknownLabelIds)).numpy(),\n",
    "                                     (predictions + 1e-5).index_select(1, torch.LongTensor(unknownLabelIds)).numpy(),\n",
    "                                    average = 'macro'))\n",
    "    \n",
    "    return old_meanAP, new_meanAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that once ***unknown set*** and ***known set*** are regenerated, meanAP score could be different from the numbers reported in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanAP of test split without feedback-prop: 22.9942420978\n",
      "meanAP of test split with layer-wise feedback-prop: 25.2597447873\n"
     ]
    }
   ],
   "source": [
    "mAP_base, mAP_lf = feedback_prop_lf_test(LF_model, knownLabelIds, unknownLabelIds, layers=['conv13'], num_iterations=10, lr=3e-3)\n",
    "print('meanAP of test split without feedback-prop: {}\\nmeanAP of test split with layer-wise feedback-prop: {}'.format(mAP_base, mAP_lf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Feedback-prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF(nn.Module):\n",
    "\n",
    "    def __init__(self, n_categories):\n",
    "        super(RF, self).__init__()\n",
    "       \n",
    "        self.n_categories = n_categories\n",
    "        self.base_network = models.resnet18(pretrained = True)\n",
    "        \n",
    "        self.base_network.fc = nn.Conv2d(512, n_categories, 1)\n",
    "        \n",
    "        self.layers = [\n",
    "            ('input_image', lambda x:x),\n",
    "            ('conv1', lambda x: self.base_network.conv1(x)),\n",
    "            ('conv5', lambda x: self.base_network.layer1(self.base_network.maxpool(\n",
    "                self.base_network.relu(self.base_network.bn1(x))))),\n",
    "            ('conv9',  lambda x: self.base_network.layer2(x)),\n",
    "            ('conv13', lambda x: self.base_network.layer3(x)),\n",
    "            ('conv17', lambda x: self.base_network.layer4(x)),\n",
    "            ('fc', lambda x: self.base_network.fc(x)),\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, aux={}):\n",
    "        for name, operator in self.layers:\n",
    "            x = operator(x)\n",
    "            if name in aux:\n",
    "                x = x + aux[name]\n",
    "            setattr(self, name, x)\n",
    "        # Take the max for each prediction map.\n",
    "        return x.max(dim = 2, keepdim=True)[0].max(dim = 3, keepdim=True)[0].squeeze()\n",
    "    \n",
    "    def partial_forward(self, start, aux={}):\n",
    "        skip = True\n",
    "        for name, operator in self.layers:\n",
    "            if name == start:\n",
    "                x = getattr(self, name)\n",
    "                x = x + aux[name]\n",
    "                skip = False\n",
    "            elif skip:\n",
    "                continue\n",
    "            else:\n",
    "                x = operator(x)\n",
    "                if name in aux:\n",
    "                    x = x + aux[name]\n",
    "                    \n",
    "        return x.max(dim = 2, keepdim=True)[0].max(dim = 3, keepdim=True)[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint (epoch 41)\n"
     ]
    }
   ],
   "source": [
    "# Prepare model.\n",
    "RF_model = RF(1000)\n",
    "RF_model = nn.DataParallel(RF_model).cuda()\n",
    "checkpoint = torch.load(os.path.join(args.logDir, 'model_best.pth.tar'))\n",
    "args.startEpoch = checkpoint['epoch']\n",
    "best_error = checkpoint['error']\n",
    "RF_model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"=> loaded checkpoint (epoch {})\".format(checkpoint['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feedback_prop_rf_val(net,knownLabelIds, unknownLabelIds, layers=['input_a'], num_iterations=20, lr=1e-3):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = defaultdict(list)\n",
    "    t = tqdm(testLoader, desc=\"Evaluating on Val:\")\n",
    "    t_knownLabelIds   = torch.LongTensor(knownLabelIds).cuda()\n",
    "    t_unknownLabelIds = torch.LongTensor(unknownLabelIds).cuda()\n",
    "    \n",
    "    for batch_idx, (data, target, imageIds) in enumerate(t):\n",
    "        # Prepare inputs.\n",
    "#         if batch_idx == 10: break\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # Inference.\n",
    "        output = net(data)\n",
    "        # Check the unobserved loss.\n",
    "        knownLabelPredictions = output.index_select(1, Variable(t_knownLabelIds))\n",
    "        knownLabelValues = target.index_select(1, Variable(t_knownLabelIds))\n",
    "        unknownLabelPredictions = output.index_select(1, Variable(t_unknownLabelIds))\n",
    "        unknownLabelValues = target.index_select(1, Variable(t_unknownLabelIds))\n",
    "        \n",
    "        aux = {}\n",
    "        for layer in layers:\n",
    "            aux_activation = torch.FloatTensor(getattr(net.module, layer).data.size()).zero_().cuda()\n",
    "            aux[layer] = Variable(aux_activation, requires_grad=True)\n",
    "        \n",
    "        activation = Variable(getattr(net.module, layers[0]).data, requires_grad=True)\n",
    "        setattr(net.module, layers[0], activation)\n",
    "            \n",
    "        optimizer = optim.Adam([aux[name] for name in aux], lr = lr, weight_decay = 1e-4)\n",
    "        for iteration in range(0, num_iterations):\n",
    "            output = net.module.partial_forward(layers[0], aux=aux)\n",
    "            knownLabelPredictions = output.index_select(1, Variable(t_knownLabelIds))\n",
    "            loss = F.binary_cross_entropy_with_logits(knownLabelPredictions, knownLabelValues)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            results[iteration].append((imageIds, output.data.cpu(), target.data.cpu()))\n",
    "        output = net.module.partial_forward(layers[0], aux=aux)\n",
    "        results[iteration + 1].append((imageIds, output.data.cpu(), target.data.cpu()))\n",
    "\n",
    "        # Logging information.\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += torch.gather(target.data, 1, pred).cpu().sum()\n",
    "        t.set_postfix(correct = str(correct))\n",
    "    \n",
    "    predictions = dict()\n",
    "    for iteration in results.keys():\n",
    "        predictions[iteration] = torch.cat([entry[1] for entry in results[iteration]], 0)\n",
    "    targets = torch.cat([entry[2] for entry in results[0]], 0)\n",
    "    \n",
    "    meanAP_unknown = list()\n",
    "    meanAP_known = list()\n",
    "    unknown_targets = targets.index_select(1, torch.LongTensor(unknownLabelIds)).numpy()\n",
    "    known_targets = targets.index_select(1, torch.LongTensor(knownLabelIds)).numpy()\n",
    "    for iteration in range(len(results)):\n",
    "        meanAP_unknown.append(100 * ( average_precision_score(unknown_targets,\n",
    "            (predictions[iteration] + 1e-5).index_select(1, torch.LongTensor(unknownLabelIds)).numpy(), average='macro')))\n",
    "        meanAP_known.append(100 * ( average_precision_score(known_targets,\n",
    "            (predictions[iteration] + 1e-5).index_select(1, torch.LongTensor(knownLabelIds)).numpy(), average='macro')))\n",
    "\n",
    "    \n",
    "    return meanAP_unknown, meanAP_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d8814e6d99479cae9e3117ecdbf06c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of iteration for max meanAP:', 10)\n"
     ]
    }
   ],
   "source": [
    "meanAP_unknown, meanAP_known = feedback_prop_rf_val(\n",
    "    RF_model, knownLabelIds, unknownLabelIds, layers=['conv13'], num_iterations=20, lr=3e-3)\n",
    "print(\"number of iteration for max meanAP:\", np.argmax(np.asarray(meanAP_unknown)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f12f490c510>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1340267c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13469cf790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'meanAP': meanAP_unknown}, index = range(0, 21))\n",
    "df.index.name = \"epochs\"\n",
    "plt.figure()\n",
    "df.plot(title=' '.join('conv13'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune parameters(learning_rate and num_iterations) on val set and apply on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feedback_prop_rf_test(net, knownLabelIds, unknownLabelIds, layers=['input_a'], num_iterations=20, lr=1e-3):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = list()\n",
    "    t = tqdm(testLoader, desc=\"Evaluating on Test:\")\n",
    "    t_knownLabelIds   = torch.LongTensor(knownLabelIds).cuda()\n",
    "    t_unknownLabelIds = torch.LongTensor(unknownLabelIds).cuda()\n",
    "    \n",
    "    for batch_idx, (data, target, imageIds) in enumerate(t):\n",
    "        # Prepare inputs.\n",
    "#         if batch_idx == 3: break\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # Inference.\n",
    "        output = net(data)\n",
    "        # Check the unobserved loss.\n",
    "        knownLabelPredictions = output.index_select(1, Variable(t_knownLabelIds))\n",
    "        knownLabelValues = target.index_select(1, Variable(t_knownLabelIds))\n",
    "        unknownLabelPredictions = output.index_select(1, Variable(t_unknownLabelIds))\n",
    "        unknownLabelValues = target.index_select(1, Variable(t_unknownLabelIds))\n",
    "        \n",
    "        aux = {}\n",
    "        for layer in layers:\n",
    "            aux_activation = torch.FloatTensor(getattr(net.module, layer).data.size()).zero_().cuda()\n",
    "            aux[layer] = Variable(aux_activation, requires_grad=True)\n",
    "        \n",
    "        activation = Variable(getattr(net.module, layers[0]).data, requires_grad=True)\n",
    "        setattr(net.module, layers[0], activation)\n",
    "            \n",
    "        optimizer = optim.Adam([aux[name] for name in aux], lr = lr, weight_decay = 1e-4)\n",
    "        for iteration in range(0, num_iterations + 1):\n",
    "            output = net.module.partial_forward(layers[0], aux=aux)\n",
    "            knownLabelPredictions = output.index_select(1, Variable(t_knownLabelIds))\n",
    "            loss = F.binary_cross_entropy_with_logits(knownLabelPredictions, knownLabelValues)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        output = net.module.partial_forward(layers[0], aux=aux)\n",
    "\n",
    "        # Logging information.\n",
    "        results.append((imageIds, output.data.cpu(), target.data.cpu(), unknownLabelPredictions.data.cpu()))\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += torch.gather(target.data, 1, pred).cpu().sum()\n",
    "        t.set_postfix(correct = str(correct))\n",
    "    \n",
    "    predictions = torch.cat([entry[1] for entry in results], 0)\n",
    "    targets = torch.cat([entry[2] for entry in results], 0)\n",
    "    ori_predictions = torch.cat([entry[3] for entry in results], 0)\n",
    "    old_meanAP = 100 * (average_precision_score(targets.index_select(1, torch.LongTensor(unknownLabelIds)).numpy(),\n",
    "                                     (ori_predictions + 1e-5).numpy(),\n",
    "                                    average = 'macro'))\n",
    "    new_meanAP = 100 * (average_precision_score(targets.index_select(1, torch.LongTensor(unknownLabelIds)).numpy(),\n",
    "                                     (predictions + 1e-5).index_select(1, torch.LongTensor(unknownLabelIds)).numpy(),\n",
    "                                    average = 'macro'))\n",
    "    \n",
    "    return old_meanAP, new_meanAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30690574940742ebbf4db9299136a14e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanAP of test split without feedback-prop: 22.9942420978\n",
      "meanAP of test split with residual feedback-prop: 25.6912361887\n"
     ]
    }
   ],
   "source": [
    "mAP_base, mAP_rf = feedback_prop_rf_test(RF_model, knownLabelIds, unknownLabelIds, layers=['conv13'], num_iterations=10, lr=3e-3)\n",
    "print('meanAP of test split without feedback-prop: {}\\nmeanAP of test split with residual feedback-prop: {}'.format(mAP_base, mAP_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
